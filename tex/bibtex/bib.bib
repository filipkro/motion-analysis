@inproceedings{Wang2017,
abstract = {We propose a simple but strong baseline for time series classification from scratch with deep neural networks. Our proposed baseline models are pure end-to-end without any heavy preprocessing on the raw data or feature crafting. The proposed Fully Convolutional Network (FCN) achieves premium performance to other state-of-the-art approaches and our exploration of the very deep neural networks with the ResNet structure is also competitive. The global average pooling in our convolutional model enables the exploitation of the Class Activation Map (CAM) to find out the contributing region in the raw data for the specific labels. Our models provides a simple choice for the real world application and a good starting point for the future research. An overall analysis is provided to discuss the generalization capability of our models, learned features, network structures and the classification semantics.},
archivePrefix = {arXiv},
arxivId = {1611.06455},
author = {Wang, Zhiguang and Yan, Weizhong and Oates, Tim},
booktitle = {Proceedings of the International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.2017.7966039},
eprint = {1611.06455},
isbn = {9781509061815},
month = {jun},
pages = {1578--1585},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Time series classification from scratch with deep neural networks: A strong baseline}},
volume = {2017-May},
year = {2017}
}
@article{IsmailFawaz2019,
abstract = {Time Series Classification (TSC) is an important and challenging problem in data mining. With the increase of time series data availability, hundreds of TSC algorithms have been proposed. Among these methods, only a few have considered Deep Neural Networks (DNNs) to perform this task. This is surprising as deep learning has seen very successful applications in the last years. DNNs have indeed revolutionized the field of computer vision especially with the advent of novel deeper architectures such as Residual and Convolutional Neural Networks. Apart from images, sequential data such as text and audio can also be processed with DNNs to reach state-of-the-art performance for document classification and speech recognition. In this article, we study the current state-of-the-art performance of deep learning algorithms for TSC by presenting an empirical study of the most recent DNN architectures for TSC. We give an overview of the most successful deep learning applications in various time series domains under a unified taxonomy of DNNs for TSC. We also provide an open source deep learning framework to the TSC community where we implemented each of the compared approaches and evaluated them on a univariate TSC benchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By training 8730 deep learning models on 97 time series datasets, we propose the most exhaustive study of DNNs for TSC to date.},
archivePrefix = {arXiv},
arxivId = {1809.04356},
author = {{Ismail Fawaz}, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre Alain},
doi = {10.1007/s10618-019-00619-1},
eprint = {1809.04356},
file = {:home/filipkr/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ismail Fawaz et al. - 2019 - Deep learning for time series classification a review.pdf:pdf},
issn = {1573756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Classification,Deep learning,Review,Time series},
month = {jul},
number = {4},
pages = {917--963},
publisher = {Springer New York LLC},
title = {{Deep learning for time series classification: a review}},
url = {https://doi.org/10.1007/s10618-019-00619-1},
volume = {33},
year = {2019}
}
@inproceedings{Zhang2020,
abstract = {While being the de facto standard coordinate representation in human pose estimation, heatmap is never systematically investigated in the literature, to our best knowledge. This work fills this gap by studying the coordinate representation with a particular focus on the heatmap. Interestingly, we found that the process of decoding the predicted heatmaps into the final joint coordinates in the original image space is surprisingly significant for human pose estimation performance, which nevertheless was not recognised before. In light of the discovered importance, we further probe the design limitations of the standard coordinate decoding method widely used by existing methods, and propose a more principled distribution-aware decoding method. Meanwhile, we improve the standard coordinate encoding process (i.e. transforming ground-truth coordinates to heatmaps) by generating accurate heatmap distributions for unbiased model training. Taking the two together, we formulate a novel Distribution-Aware coordinate Representation of Keypoint (DARK) method. Serving as a model-agnostic plug-in, DARK significantly improves the performance of a variety of state-of-the-art human pose estimation models. Extensive experiments show that DARK yields the best results on two common benchmarks, MPII and COCO, consistently validating the usefulness and effectiveness of our novel coordinate representation idea.},
archivePrefix = {arXiv},
arxivId = {1910.06278},
author = {Zhang, Feng and Zhu, Xiatian and Dai, Hanbin and Ye, Mao and Zhu, Ce},
doi = {10.1109/cvpr42600.2020.00712},
eprint = {1910.06278},
mendeley-groups = {xjob},
month = {aug},
pages = {7091--7100},
publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
title = {{Distribution-Aware Coordinate Representation for Human Pose Estimation}},
year = {2020}
}

@misc{mmpose,
title = {{MMP}ose - {O}pen{MML}ab {P}ose {E}stimation {T}oolbox and {B}enchmark},
note = {Available at \url{https://github.com/open-mmlab/mmpose}},
url = {https://github.com/open-mmlab/mmpose}}
@inproceedings{Lin2014,
abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model. {\textcopyright} 2014 Springer International Publishing.},
archivePrefix = {arXiv},
arxivId = {1405.0312},
author = {Lin, Tsung Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'{a}}r, Piotr and Zitnick, C. Lawrence},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-10602-1_48},
eprint = {1405.0312},
file = {:home/filipkr/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - 2014 - Microsoft COCO Common objects in context.pdf:pdf},
issn = {16113349},
mendeley-groups = {xjob},
month = {may},
number = {PART 5},
pages = {740--755},
publisher = {Springer Verlag},
title = {{Microsoft COCO: Common objects in context}},
url = {https://arxiv.org/abs/1405.0312v3},
volume = {8693 LNCS},
year = {2014}
}
@inproceedings{Pavllo2019,
abstract = {In this work, we demonstrate that 3D poses in video can be effectively estimated with a fully convolutional model based on dilated temporal convolutions over 2D keypoints. We also introduce back-projection, a simple and effective semi-supervised training method that leverages unlabeled video data. We start with predicted 2D keypoints for unlabeled video, then estimate 3D poses and finally back-project to the input 2D keypoints. In the supervised setting, our fully-convolutional model outperforms the previous best result from the literature by 6 mm mean per-joint position error on Human3.6M, corresponding to an error reduction of 11{\%}, and the model also shows significant improvements on HumanEva-I. Moreover, experiments with back-projection show that it comfortably outperforms previous state-of-the-art results in semi-supervised settings where labeled data is scarce. Code and models are available at https://github.com/facebookresearch/VideoPose3D.},
archivePrefix = {arXiv},
arxivId = {1811.11742},
author = {Pavllo, Dario and Feichtenhofer, Christoph and Grangier, David and Auli, Michael},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2019.00794},
eprint = {1811.11742},
isbn = {9781728132938},
issn = {10636919},
keywords = {And Body Pose,Face,Gesture},
mendeley-groups = {xjob},
month = {jun},
pages = {7745--7754},
publisher = {IEEE Computer Society},
title = {{3D human pose estimation in video with temporal convolutions and semi-supervised training}},
volume = {2019-June},
year = {2019}
}
